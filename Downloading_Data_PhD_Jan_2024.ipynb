{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rsarpongstreetor/rl/blob/main/Downloading_Data_PhD_Jan_2024.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHGY6bqAtd_O"
      },
      "source": [
        "### Data Gathering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceFu_f9E1yrU"
      },
      "source": [
        "# Downloading from websites\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jb3anocBtb8O",
        "outputId": "bebe19ea-b0e4-4b9e-c98d-62ac810ba0d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.11.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.5)\n",
            "Requirement already satisfied: furl in /usr/local/lib/python3.10/dist-packages (2.1.3)\n",
            "Requirement already satisfied: six>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from furl) (1.16.0)\n",
            "Requirement already satisfied: orderedmultidict>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from furl) (1.0.1)\n",
            "Requirement already satisfied: html-table-parser-python3 in /usr/local/lib/python3.10/dist-packages (0.3.1)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "                                             response  \\\n",
            "0   {'total': '258', 'dateFormat': 'YYYY-MM-DD', '...   \n",
            "1   {'total': '261', 'dateFormat': 'YYYY-MM-DD', '...   \n",
            "2   {'total': '257', 'dateFormat': 'YYYY-MM-DD', '...   \n",
            "3   {'total': '255', 'dateFormat': 'YYYY-MM-DD', '...   \n",
            "4   {'total': '250', 'dateFormat': 'YYYY-MM-DD', '...   \n",
            "5   {'total': '253', 'dateFormat': 'YYYY-MM-DD', '...   \n",
            "6   {'total': '252', 'dateFormat': 'YYYY-MM-DD', '...   \n",
            "7   {'total': '252', 'dateFormat': 'YYYY-MM-DD', '...   \n",
            "8   {'total': '248', 'dateFormat': 'YYYY-MM-DD', '...   \n",
            "9   {'total': '250', 'dateFormat': 'YYYY-MM-DD', '...   \n",
            "10  {'total': '252', 'dateFormat': 'YYYY-MM-DD', '...   \n",
            "11  {'total': '251', 'dateFormat': 'YYYY-MM-DD', '...   \n",
            "12  {'total': '257', 'dateFormat': 'YYYY-MM-DD', '...   \n",
            "13  {'total': '256', 'dateFormat': 'YYYY-MM-DD', '...   \n",
            "14  {'total': '256', 'dateFormat': 'YYYY-MM-DD', '...   \n",
            "15  {'total': '254', 'dateFormat': 'YYYY-MM-DD', '...   \n",
            "16  {'total': '259', 'dateFormat': 'YYYY-MM-DD', '...   \n",
            "17  {'total': '258', 'dateFormat': 'YYYY-MM-DD', '...   \n",
            "18  {'total': '256', 'dateFormat': 'YYYY-MM-DD', '...   \n",
            "19  {'total': '254', 'dateFormat': 'YYYY-MM-DD', '...   \n",
            "20  {'total': '253', 'dateFormat': 'YYYY-MM-DD', '...   \n",
            "21  {'total': '15', 'dateFormat': 'YYYY-MM-DD', 'f...   \n",
            "\n",
            "                                              request apiVersion  \\\n",
            "0   {'command': '/v2/petroleum/pri/spt/data/', 'pa...      2.1.5   \n",
            "1   {'command': '/v2/petroleum/pri/spt/data/', 'pa...      2.1.5   \n",
            "2   {'command': '/v2/petroleum/pri/spt/data/', 'pa...      2.1.5   \n",
            "3   {'command': '/v2/petroleum/pri/spt/data/', 'pa...      2.1.5   \n",
            "4   {'command': '/v2/petroleum/pri/spt/data/', 'pa...      2.1.5   \n",
            "5   {'command': '/v2/petroleum/pri/spt/data/', 'pa...      2.1.5   \n",
            "6   {'command': '/v2/petroleum/pri/spt/data/', 'pa...      2.1.5   \n",
            "7   {'command': '/v2/petroleum/pri/spt/data/', 'pa...      2.1.5   \n",
            "8   {'command': '/v2/petroleum/pri/spt/data/', 'pa...      2.1.5   \n",
            "9   {'command': '/v2/petroleum/pri/spt/data/', 'pa...      2.1.5   \n",
            "10  {'command': '/v2/petroleum/pri/spt/data/', 'pa...      2.1.5   \n",
            "11  {'command': '/v2/petroleum/pri/spt/data/', 'pa...      2.1.5   \n",
            "12  {'command': '/v2/petroleum/pri/spt/data/', 'pa...      2.1.5   \n",
            "13  {'command': '/v2/petroleum/pri/spt/data/', 'pa...      2.1.5   \n",
            "14  {'command': '/v2/petroleum/pri/spt/data/', 'pa...      2.1.5   \n",
            "15  {'command': '/v2/petroleum/pri/spt/data/', 'pa...      2.1.5   \n",
            "16  {'command': '/v2/petroleum/pri/spt/data/', 'pa...      2.1.5   \n",
            "17  {'command': '/v2/petroleum/pri/spt/data/', 'pa...      2.1.5   \n",
            "18  {'command': '/v2/petroleum/pri/spt/data/', 'pa...      2.1.5   \n",
            "19  {'command': '/v2/petroleum/pri/spt/data/', 'pa...      2.1.5   \n",
            "20  {'command': '/v2/petroleum/pri/spt/data/', 'pa...      2.1.5   \n",
            "21  {'command': '/v2/petroleum/pri/spt/data/', 'pa...      2.1.5   \n",
            "\n",
            "   ExcelAddInVersion  \n",
            "0              2.1.0  \n",
            "1              2.1.0  \n",
            "2              2.1.0  \n",
            "3              2.1.0  \n",
            "4              2.1.0  \n",
            "5              2.1.0  \n",
            "6              2.1.0  \n",
            "7              2.1.0  \n",
            "8              2.1.0  \n",
            "9              2.1.0  \n",
            "10             2.1.0  \n",
            "11             2.1.0  \n",
            "12             2.1.0  \n",
            "13             2.1.0  \n",
            "14             2.1.0  \n",
            "15             2.1.0  \n",
            "16             2.1.0  \n",
            "17             2.1.0  \n",
            "18             2.1.0  \n",
            "19             2.1.0  \n",
            "20             2.1.0  \n",
            "21             2.1.0  \n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "                 Date    Brent\n",
            "Date                          \n",
            "2003-01-02 2003-01-02  30.3125\n",
            "2003-01-03 2003-01-03  31.4375\n",
            "2003-01-04 2003-01-04      NaN\n",
            "2003-01-05 2003-01-05      NaN\n",
            "2003-01-06 2003-01-06  31.4375\n",
            "...               ...      ...\n",
            "2024-01-18 2024-01-18  81.0625\n",
            "2024-01-19 2024-01-19  80.6875\n",
            "2024-01-20 2024-01-20      NaN\n",
            "2024-01-21 2024-01-21      NaN\n",
            "2024-01-22 2024-01-22  81.6875\n",
            "\n",
            "[7691 rows x 2 columns]\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Wrote all symbols to JSON file\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "                 Date       WTI\n",
            "Date                           \n",
            "2003-01-02 2003-01-02  31.96875\n",
            "2003-01-03 2003-01-03  33.25000\n",
            "2003-01-04 2003-01-04       NaN\n",
            "2003-01-05 2003-01-05       NaN\n",
            "2003-01-06 2003-01-06  32.28125\n",
            "...               ...       ...\n",
            "2024-01-18 2024-01-18  74.31250\n",
            "2024-01-19 2024-01-19  73.68750\n",
            "2024-01-20 2024-01-20       NaN\n",
            "2024-01-21 2024-01-21       NaN\n",
            "2024-01-22 2024-01-22  75.25000\n",
            "\n",
            "[7691 rows x 2 columns]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "XMLSyntaxError",
          "evalue": "StartTag: invalid element name, line 1, column 2 (<string>, line 1)",
          "traceback": [
            "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
            "  File \u001b[1;32m\"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m3553\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \u001b[1;32m\"<ipython-input-2-a9b07247a435>\"\u001b[0m, line \u001b[1;32m769\u001b[0m, in \u001b[1;35m<cell line: 769>\u001b[0m\n    CCCC=OPEC()\n",
            "  File \u001b[1;32m\"<ipython-input-2-a9b07247a435>\"\u001b[0m, line \u001b[1;32m524\u001b[0m, in \u001b[1;35mOPEC\u001b[0m\n    OPECPrice=pd.read_xml('http://tempuri.org/basketDayArchives.xsd')\n",
            "  File \u001b[1;32m\"/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\"\u001b[0m, line \u001b[1;32m331\u001b[0m, in \u001b[1;35mwrapper\u001b[0m\n    return func(*args, **kwargs)\n",
            "  File \u001b[1;32m\"/usr/local/lib/python3.10/dist-packages/pandas/io/xml.py\"\u001b[0m, line \u001b[1;32m1088\u001b[0m, in \u001b[1;35mread_xml\u001b[0m\n    return _parse(\n",
            "  File \u001b[1;32m\"/usr/local/lib/python3.10/dist-packages/pandas/io/xml.py\"\u001b[0m, line \u001b[1;32m827\u001b[0m, in \u001b[1;35m_parse\u001b[0m\n    data_dicts = p.parse_data()\n",
            "  File \u001b[1;32m\"/usr/local/lib/python3.10/dist-packages/pandas/io/xml.py\"\u001b[0m, line \u001b[1;32m551\u001b[0m, in \u001b[1;35mparse_data\u001b[0m\n    self.xml_doc = self._parse_doc(self.path_or_buffer)\n",
            "  File \u001b[1;32m\"/usr/local/lib/python3.10/dist-packages/pandas/io/xml.py\"\u001b[0m, line \u001b[1;32m636\u001b[0m, in \u001b[1;35m_parse_doc\u001b[0m\n    doc = fromstring(\n",
            "  File \u001b[1;32m\"src/lxml/etree.pyx\"\u001b[0m, line \u001b[1;32m3264\u001b[0m, in \u001b[1;35mlxml.etree.fromstring\u001b[0m\n",
            "  File \u001b[1;32m\"src/lxml/parser.pxi\"\u001b[0m, line \u001b[1;32m1916\u001b[0m, in \u001b[1;35mlxml.etree._parseMemoryDocument\u001b[0m\n",
            "  File \u001b[1;32m\"src/lxml/parser.pxi\"\u001b[0m, line \u001b[1;32m1803\u001b[0m, in \u001b[1;35mlxml.etree._parseDoc\u001b[0m\n",
            "  File \u001b[1;32m\"src/lxml/parser.pxi\"\u001b[0m, line \u001b[1;32m1144\u001b[0m, in \u001b[1;35mlxml.etree._BaseParser._parseDoc\u001b[0m\n",
            "  File \u001b[1;32m\"src/lxml/parser.pxi\"\u001b[0m, line \u001b[1;32m618\u001b[0m, in \u001b[1;35mlxml.etree._ParserContext._handleParseResultDoc\u001b[0m\n",
            "  File \u001b[1;32m\"src/lxml/parser.pxi\"\u001b[0m, line \u001b[1;32m728\u001b[0m, in \u001b[1;35mlxml.etree._handleParseResult\u001b[0m\n",
            "\u001b[0;36m  File \u001b[0;32m\"src/lxml/parser.pxi\"\u001b[0;36m, line \u001b[0;32m657\u001b[0;36m, in \u001b[0;35mlxml.etree._raiseParseError\u001b[0;36m\u001b[0m\n",
            "\u001b[0;36m  File \u001b[0;32m\"<string>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31mXMLSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m StartTag: invalid element name, line 1, column 2\n"
          ]
        }
      ],
      "source": [
        "!pip install beautifulsoup4\n",
        "!pip install furl\n",
        "!pip install html-table-parser-python3\n",
        "\n",
        "from datetime import datetime, timedelta, date\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import linear_model\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import urllib.request\n",
        "from pprint import pprint\n",
        "from html_table_parser.parser import HTMLTableParser\n",
        "import requests\n",
        "import json\n",
        "import os\n",
        "from google.colab import drive\n",
        "from pandas.core.generic import DataFrameFormatter\n",
        "from numpy.core.fromnumeric import reshape\n",
        "from pandas.core.arrays import period\n",
        "from pandas.core.generic import DataFrameFormatter\n",
        "from numpy.core.fromnumeric import reshape\n",
        "import xml.etree.ElementTree as ET\n",
        "from google.colab import data_table\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "\n",
        "# Opens a website and read its\n",
        "# binary contents (HTTP Response Body)\n",
        "todays_date = date.today()\n",
        "\n",
        "################################################\n",
        "###Brent Crude oil Price\n",
        "def Brent():\n",
        "  #Fetching the bulk data from website  and reorganizing on to google drive\n",
        "  import requests\n",
        "  import json\n",
        "  import os\n",
        "  import pandas as pd\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "  Gh1files=[]\n",
        "  json_path = f\"{os.getcwd()}\\\\JSON\"\n",
        "  url = \" https://api.eia.gov/v2/petroleum/pri/spt/data/?frequency=daily&data[0]=value&facets[series][]=RBRTE&start=1995-01-01&sort[0][column]=period&sort[0][direction]=desc&offset=0&length=5000&api_key=7e361b53e231aaf90ac6dcd91c0dc07d\"\n",
        "  headers = {\"api_key\":\"7e361b53e231aaf90ac6dcd91c0dc07d\",\"host\":\"api.eia.gov\"}\n",
        "\n",
        "  # Change ticker symbol in the query string in each loop\n",
        "  #while loop\n",
        "  year = 2002\n",
        "  while year < todays_date.year:\n",
        "    year += 1\n",
        "\n",
        "    querystring={'frequency':'daily','data[0]':'value','start':f'{year}-01-01','end':f'{year}-12-31','offset':'0','length':'5000'}\n",
        "  # print(f\"year = {year}\")\n",
        "\n",
        "\n",
        "\n",
        "      # Get a new request in every loop\n",
        "    response = requests.request(\"GET\", url, headers=headers, params=querystring)\n",
        "    #print(f\"Done request {year} data\")\n",
        "\n",
        "      # Write the response into a JSON file in the JSON folder\n",
        "    with open(f\"/content/drive/MyDrive/deep learning codes/EIAAPI_DOWNLOAD/{year}prices1_year.json\", \"w\") as outfile:\n",
        "      json.dump(response.json(), outfile)\n",
        "\n",
        "\n",
        "    #concantenating files\n",
        "    Gh1files.append(response.json())\n",
        "\n",
        "    dff = pd.DataFrame(Gh1files)\n",
        "\n",
        "\n",
        "\n",
        "      # Output message to indicate a successful loop\n",
        "  # print(f\"Wrote {year} to JSON file\")\n",
        "  # print(\"\")\n",
        "  # print('-'*30)\n",
        "  # print(\"\")\n",
        "  else:\n",
        "\n",
        "      # Output message to indicate the loop is complete\n",
        "   # print(f\"Wrote all symbols to JSON file\")\n",
        "\n",
        "    print(dff)\n",
        "\n",
        "  file =open(f\"/content/drive/MyDrive/deep learning codes/EIAAPI_DOWNLOAD/solutions/mergedata/Mergeddata1.json\", \"w\")\n",
        "  for item in Gh1files:\n",
        "      file.write(f\"{item}'\\n'\")\n",
        "  file.close()\n",
        "\n",
        "  #########################################################################################################################################\n",
        "\n",
        "\n",
        "  #Fetching Data and Reorganizing it from google drive\n",
        "\n",
        "  from pandas.core.generic import DataFrameFormatter\n",
        "  from numpy.core.fromnumeric import reshape\n",
        "  from pandas.core.arrays import period\n",
        "  from datetime import datetime\n",
        "  import requests\n",
        "  import json\n",
        "  import os\n",
        "  import pandas as pd\n",
        "  import numpy as np\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "  DData=[]\n",
        "  DD=[]\n",
        "  serK=[]\n",
        "  serH=[]\n",
        "  serr=[]\n",
        "  serrr=[]\n",
        "  ser=[]\n",
        "  Price=[]\n",
        "  year = 2002\n",
        "  while year < todays_date.year:\n",
        "    year += 1\n",
        "\n",
        "    ppperiod=[]\n",
        "    vvvvalue=[]\n",
        "    # Open the prices.json file\n",
        "    with open(f\"/content/drive/MyDrive/deep learning codes/EIAAPI_DOWNLOAD/{year}prices1_year.json\") as file:\n",
        "      # Load its content and make a new dictionary\n",
        "        DData=json.load(file)\n",
        "        for response in DData:\n",
        "          DDData=(DData[\"response\"])\n",
        "\n",
        "          for data in DDData:\n",
        "            KK=[]\n",
        "            hh=[]\n",
        "\n",
        "            DDDData=(DDData[\"data\"])\n",
        "            length = len(DDDData)\n",
        "            l=[]\n",
        "            i=0\n",
        "            while i < length:\n",
        "              v=[]\n",
        "              p=[]\n",
        "              k=DDDData[i]\n",
        "              v=k['value']\n",
        "\n",
        "              pp=(k['period'])\n",
        "              p=datetime.strptime(pp,'%Y-%m-%d').date()\n",
        "\n",
        "              KK.append(p)\n",
        "              hh.append(v)\n",
        "              i+=1\n",
        "        serK.append(KK)\n",
        "        serH.append(hh)\n",
        "  flat_list1 = []\n",
        "  for sublist in serH:\n",
        "          for item in sublist:\n",
        "            flat_list1.append(item)\n",
        "  flat_list = []\n",
        "  for sublist in serK:\n",
        "          for item in sublist:\n",
        "            flat_list.append(item)\n",
        "  else:\n",
        "    BrentPrice = list(zip(flat_list,np.float16(flat_list1)))\n",
        "    BrentPrice=pd.DataFrame(BrentPrice)\n",
        "\n",
        "\n",
        "    BrentPrice.columns=['Date','Brent']\n",
        "    BrentPrice['Date']=pd.to_datetime(BrentPrice['Date'],infer_datetime_format=True)\n",
        "    BrentPrice.index=BrentPrice['Date']\n",
        "    BrentPrice.sort_index\n",
        "  # print(BrentPrice)\n",
        "\n",
        "\n",
        "    #title = f'Brent Crude oil Prices '\n",
        "  #recentdt = BrentPrice.index[-1].strftime('%B %Y')\n",
        "  #recentval = round(BrentPrice[-1], 1)\n",
        "  #recent = f'Most recent: {recentdt}: {recentval}'\n",
        "  #source = 'Source: EIA'\n",
        "  #rint(BrentPrice)\n",
        "  #Basic plot\n",
        "  #plot = BrentPrice.plot(title=title, colormap='copper',color='blue')\n",
        "  #plot = plot.set_xlabel(f'{recent}; {source}')\n",
        "  #BrentPrice.fillna(method=\"ffill\", axis=\"index\", inplace=True, limit=None, downcast=\"infer\")\n",
        "  BBrentPrice=pd.date_range(start=f'{(BrentPrice[\"Date\"]).min()}', end=f'{BrentPrice[\"Date\"].max()}', periods=None, freq=\"D\", tz=None, normalize=False, name=None, inclusive='both')\n",
        "  BBrentPrice=pd.DataFrame(BBrentPrice)\n",
        "  BBrentPrice.columns=['Date']\n",
        "  BBrentPrice.index=BBrentPrice['Date']\n",
        "  BBBrentPrice=pd.concat([BBrentPrice['Date'], BrentPrice['Brent']], axis=1, join='outer', ignore_index=False, keys=None, levels=None, names=None, verify_integrity=True, sort=True, copy=None)\n",
        "  #BBBrentPrice.ffillna()\n",
        "  BBBrentPrice.index=pd.to_datetime(BBBrentPrice.index,format='%Y-%m-%d',infer_datetime_format=True)\n",
        "\n",
        "  #BBBBrentPrice=pd.Series(BBBrentPrice['Brent'])\n",
        "\n",
        "\n",
        "  #BBBBrentPrice.reindex(BBBrentPrice['Dat'])\n",
        "  #BBBBBrentPrice=pd.DataFrame(BBBBBrentPrice)\n",
        "  #BBBBBrentPrice.columns=['Date','Brent']\n",
        " # BBBBBrentPrice['Date']=pd.to_datetime(BBBBBrentPrice['Date'],infer_datetime_format=True)\n",
        "  #BBBBBrentPrice.index=BrentPrice['Date']\n",
        "\n",
        "\n",
        "  #BBBBBrentPrice=pd.concat([BBBrentPrice['Date'], BBBBrentPrice['Brent']], axis=1, join='outer', ignore_index=False, keys=None, levels=None, names=None, verify_integrity=True, sort=True, copy=None)\n",
        " # BBBBBrentPrice.index=BBBBBrentPrice['Date']\n",
        "  #BBBBBrentPrice.index=pd.to_datetime(BBBBBrentPrice.index,infer_datetime_format=True)\n",
        "\n",
        "  recentBBBBrentPrice=BBBrentPrice.index[-1]\n",
        "  print(BBBrentPrice)\n",
        "  return BBBrentPrice\n",
        "########################################################################################################\n",
        "###  DATA\n",
        "def USSDR():\n",
        "\n",
        "    !pip install beautifulsoup4\n",
        "    !pip install furl\n",
        "    !pip install html-table-parser-python3\n",
        "\n",
        "\n",
        "    # for converting the parsed data in a\n",
        "    # pandas dataframe\n",
        "    from datetime import datetime, timedelta, date\n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "    from sklearn import linear_model\n",
        "    import matplotlib.pyplot as plt\n",
        "    from sklearn.linear_model import LinearRegression\n",
        "    import urllib.request\n",
        "    from pprint import pprint\n",
        "    from html_table_parser.parser import HTMLTableParser\n",
        "\n",
        "\n",
        "\n",
        "    # Opens a website and read its\n",
        "    # binary contents (HTTP Response Body)\n",
        "    def url_get_contents(url):\n",
        "\n",
        "      # Opens a website and read its\n",
        "      # binary contents (HTTP Response Body)\n",
        "\n",
        "      #making request to the website\n",
        "      req = urllib.request.Request(url=url)\n",
        "      f = urllib.request.urlopen(req)\n",
        "\n",
        "      #reading contents of the website\n",
        "      return f.read()\n",
        "\n",
        "    ############\n",
        "    from datetime import datetime, timedelta, date\n",
        "    today = date.today()\n",
        "\n",
        "    # initializing dates\n",
        "    test_date =today\n",
        "\n",
        "    # getting difference\n",
        "    diff = 1\n",
        "    if test_date.weekday() == 0:\n",
        "        diff = 3\n",
        "    elif test_date.weekday() == 6:\n",
        "        diff = 2\n",
        "    else :\n",
        "        diff = 1\n",
        "\n",
        "    # subtracting diff\n",
        "    res = test_date - timedelta(days=diff)\n",
        "    # printing result\n",
        "\n",
        "    #############\n",
        "    z=[f\"{res}\"]\n",
        "    zy=[0]\n",
        "    zz=list(zip (z,zy))\n",
        "    zz=pd.DataFrame(zz)\n",
        "    zz.set_index(zz[0])\n",
        "    zz[0]=pd.to_datetime(zz[0])\n",
        "    zz[0]=zz[0].astype(int)\n",
        "    xxx=zz[0].values.reshape(1, -1)\n",
        "\n",
        "    b=['2023-6-30','2002-7-20','2001-8-7','2000-12-18','1999-5-19']\n",
        "    a=[638237000000000000,631628000000000000,631328000000000000,631128000000000000,630628000000000000]\n",
        "    bb=list(zip (b,a))\n",
        "    bb=pd.DataFrame(bb)\n",
        "    bb[0]=pd.to_datetime(bb[0])\n",
        "    bb[0]=bb[0].astype(int)\n",
        "\n",
        "    x = bb[0].values.reshape(-1,1)\n",
        "    y = bb[1].values.reshape(-1,1)\n",
        "    bb.set_index(bb[0])\n",
        "    reg = LinearRegression()\n",
        "    reg.fit(x, y)\n",
        "    xxxx=[]\n",
        "        # Predict using the model\n",
        "    zz[1] = reg.predict(xxx)\n",
        "\n",
        "    xxxx=zz.iloc[0,1].astype(int)\n",
        " #631770624000000000&To=638381952000000000\n",
        "    ##############\n",
        "    from furl import furl\n",
        "\n",
        "    f=furl('https://www.imf.org/external/np/fin/ert/GUI/Pages/Report.aspx?CT=%27USA%27&EX=SDRC&P=DateRange&Fr=631770624000000000&To=638318016000000000&CF=Compressed&CUF=Period&DS=Ascending&DT=Blank')\n",
        "    f.args[\"To\"] = {f'{xxxx}'}\n",
        "    f.url\n",
        "  # print(f.url)\n",
        "    # defining the html contents of a URL.\n",
        "    xhtml = url_get_contents(f.url).decode('utf-8')\n",
        "\n",
        "    # Defining the HTMLTableParser object\n",
        "    p = HTMLTableParser()\n",
        "\n",
        "    # feeding the html contents in the\n",
        "    # HTMLTableParser object\n",
        "    p.feed(xhtml)\n",
        "\n",
        "    # Now finally obtaining the data of\n",
        "    # the table required\n",
        "    #pprint(p.tables[15])\n",
        "\n",
        "    # converting the parsed data to\n",
        "    # dataframe\n",
        "\n",
        "\n",
        "    sdrusd=pd.DataFrame(p.tables[15])\n",
        "    sdrusd=sdrusd.iloc[2:]\n",
        "\n",
        "    sdrusd.columns=sdrusd.iloc[1]\n",
        "\n",
        "    s=sdrusd.iloc[0:,0]\n",
        "\n",
        "    s=pd.to_datetime(s,infer_datetime_format=True)\n",
        "    ps=sdrusd.iloc[0:,1]\n",
        "    sdrusd=list(zip(s,ps))\n",
        "    sdrusd=pd.DataFrame(sdrusd)\n",
        "    sdrusd.columns=['Date','USD_SDR']\n",
        "    sdrusd.index=sdrusd['Date']\n",
        "\n",
        "    ssdrusd=pd.date_range(start=f'{(sdrusd[\"Date\"]).min()}', end=f'{sdrusd[\"Date\"].max()}', periods=None, freq=\"D\", tz=None, normalize=False, name=None, inclusive='both')\n",
        "    ssdrusd=pd.DataFrame(ssdrusd)\n",
        "    ssdrusd.columns=['Date']\n",
        "    ssdrusd.index=ssdrusd['Date']\n",
        "    sssdrusd=pd.concat([ssdrusd['Date'], sdrusd['USD_SDR']], axis=1, join='outer', ignore_index=False, keys=None, levels=None, names=None, verify_integrity=True, sort=True, copy=None)\n",
        "    sssdrusd.index=pd.to_datetime(sssdrusd.index,format='%Y-%m-%d',infer_datetime_format=True)\n",
        "    sssdrusd.sort_index\n",
        "   # sssdrusd.fillna(axis=1, method='ffill', inplace=True)\n",
        "    print(sssdrusd)\n",
        "    return sssdrusd\n",
        "\n",
        "#####################################################################################################\n",
        "###WTI Crude oil *Price*\n",
        "\n",
        "def WTI():\n",
        "  #Fetching the bulk data from website  and reorganizing on to google drive\n",
        "  import requests\n",
        "  import json\n",
        "  import os\n",
        "  import pandas as pd\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "  Gh1files=[]\n",
        "  json_path = f\"{os.getcwd()}\\\\JSON\"\n",
        "  url = \"https://api.eia.gov/v2/petroleum/pri/spt/data/?frequency=daily&data[0]=value&facets[series][]=RWTC&start=1995-01-01&sort[0][column]=period&sort[0][direction]=desc&offset=0&length=5000&api_key=7e361b53e231aaf90ac6dcd91c0dc07d\"\n",
        "  headers = {\"api_key\":\"7e361b53e231aaf90ac6dcd91c0dc07d\",\"host\":\"api.eia.gov\"}\n",
        "\n",
        "  # Change ticker symbol in the query string in each loop\n",
        "  #while loop\n",
        "  year = 2002\n",
        "  while year < todays_date.year:\n",
        "    year += 1\n",
        "\n",
        "    querystring={'frequency':'daily','data[0]':'value','start':f'{year}-01-01','end':f'{year}-12-31','offset':'0','length':'5000'}\n",
        "  # print(f\"year = {year}\")\n",
        "\n",
        "\n",
        "\n",
        "      # Get a new request in every loop\n",
        "    response = requests.request(\"GET\", url, headers=headers, params=querystring)\n",
        "   #print(f\"Done request {year} data\")\n",
        "\n",
        "      # Write the response into a JSON file in the JSON folder\n",
        "    with open(f\"/content/drive/MyDrive/deep learning codes/EIAAPI_DOWNLOAD/{year}pricesWTI_year.json\", \"w\") as outfile:\n",
        "      json.dump(response.json(),outfile)\n",
        "\n",
        "\n",
        "    #concantenating files\n",
        "    Gh1files.append(response.json())\n",
        "\n",
        "    dff = pd.DataFrame(Gh1files)\n",
        "\n",
        "\n",
        "\n",
        "      # Output message to indicate a successful loop\n",
        "  # print(f\"Wrote {year} to JSON file\")\n",
        "  # print(\"\")\n",
        "  # print('-'*30)\n",
        "  # print(\"\")\n",
        "  else:\n",
        "      # Output message to indicate the loop is complete\n",
        "    print(f\"Wrote all symbols to JSON file\")\n",
        "    #print(dff)\n",
        "  file =open(f\"/content/drive/MyDrive/deep learning codes/EIAAPI_DOWNLOAD/solutions/mergedata/WTIMergeddata1.json\", \"w\")\n",
        "  for item in Gh1files:\n",
        "      file.write(f\"{item}'\\n'\")\n",
        "  file.close()\n",
        "  ####################################################################################################################\n",
        "  #Fetching Data and Reorganizing it from google drive\n",
        "  from pandas.core.generic import DataFrameFormatter\n",
        "  from numpy.core.fromnumeric import reshape\n",
        "  from pandas.core.arrays import period\n",
        "  from datetime import datetime\n",
        "  import json\n",
        "  import requests\n",
        "  import os\n",
        "  import pandas as pd\n",
        "  import numpy as np\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "  DData=[]\n",
        "  DD=[]\n",
        "  serK=[]\n",
        "  serH=[]\n",
        "  serr=[]\n",
        "  serrr=[]\n",
        "  ser=[]\n",
        "  Price=[]\n",
        "  year = 2002\n",
        "  while year < todays_date.year:\n",
        "    year += 1\n",
        "\n",
        "    ppperiod=[]\n",
        "    vvvvalue=[]\n",
        "\n",
        "    # Open the prices.json file\n",
        "    with open(f\"/content/drive/MyDrive/deep learning codes/EIAAPI_DOWNLOAD/{year}pricesWTI_year.json\") as file:\n",
        "\n",
        "      # Load its content and make a new dictionary\n",
        "        DData=json.load(file)\n",
        "        for response in DData:\n",
        "          DDData=(DData[\"response\"])\n",
        "\n",
        "          for data in DDData:\n",
        "            KK=[]\n",
        "            hh=[]\n",
        "\n",
        "            DDDData=(DDData[\"data\"])\n",
        "            length = len(DDDData)\n",
        "            l=[]\n",
        "            i=0\n",
        "            while i < length:\n",
        "              v=[]\n",
        "              p=[]\n",
        "              k=DDDData[i]\n",
        "              v=k['value']\n",
        "\n",
        "              pp=(k['period'])\n",
        "              p=datetime.strptime(pp,'%Y-%m-%d').date()\n",
        "\n",
        "              KK.append(p)\n",
        "              hh.append(v)\n",
        "              i+=1\n",
        "        serK.append(KK)\n",
        "        serH.append(hh)\n",
        "  flat_list1 = []\n",
        "  for sublist in serH:\n",
        "          for item in sublist:\n",
        "            flat_list1.append(item)\n",
        "  flat_list = []\n",
        "  for sublist in serK:\n",
        "          for item in sublist:\n",
        "            flat_list.append(item)\n",
        "  else:\n",
        "    WTIPrice = list(zip(flat_list, np.float16(flat_list1)))\n",
        "    WTIPrice=pd.DataFrame(WTIPrice)\n",
        "    WTIPrice.columns=['Date','WTI']\n",
        "    WTIPrice['Date']=pd.to_datetime(WTIPrice['Date'],infer_datetime_format=True)\n",
        "    WTIPrice.index=WTIPrice['Date']\n",
        "\n",
        "    WWTIPrice=pd.date_range(start=f'{(WTIPrice[\"Date\"]).min()}', end=f'{WTIPrice[\"Date\"].max()}', periods=None, freq=\"D\", tz=None, normalize=False, name=None, inclusive='both')\n",
        "    WWTIPrice=pd.DataFrame(WWTIPrice)\n",
        "    WWTIPrice.columns=['Date']\n",
        "    WWTIPrice.index=WWTIPrice['Date']\n",
        "    WWWTIPrice=pd.concat([WWTIPrice['Date'], WTIPrice['WTI']], axis=1, join='outer', ignore_index=False, keys=None, levels=None, names=None, verify_integrity=True, sort=True, copy=None)\n",
        "\n",
        "    WWWTIPrice.index=pd.to_datetime(WWWTIPrice.index, format='%Y-%m-%d', infer_datetime_format=True)\n",
        "    #WWWTIPrice.ffill()\n",
        "   # WWWWTIPrice=pd.Series(WWWTIPrice['WTI'])\n",
        "\n",
        "   # WWWWTIPrice.reindex(method='ffill', copy=None, level=None)\n",
        "   # WWWWTIPrice.reindex(WWWTIPrice['Date'])\n",
        "\n",
        "\n",
        "\n",
        "    #WWWTIPrice.fillna(axis=0, method='ffill', inplace=True)\n",
        "    #sdrusd.fillna( method=\"ffill\", axis=\"index\", inplace=True, limit=None, downcast=\"infer\")\n",
        " #  print(sdrusd)\n",
        "\n",
        "   #print(WTIPrice)\n",
        "\n",
        "  #title = f'WTI Crude oil Prices '\n",
        "  #recentdt = WTIPrice.index[-1].strftime('%B %Y')\n",
        "  #recentval = round(WTIPrice[-1], 1)\n",
        "  #recent = f'Most recent: {recentdt}: {recentval}'\n",
        "  #source = 'Source: OPEC'\n",
        "\n",
        "  #Basic plot\n",
        "  #plot = WTIPrice.plot(title=title, colormap='copper',color='green')\n",
        "  #plot = plot.set_xlabel(f'{recent}; {source}')\n",
        "  #WTIPrice.fillna( method=\"ffill\", axis=\"index\", inplace=True, limit=None, downcast=\"infer\")\n",
        "  #WWWTIPrice['WTI'].fillna(axis=0, method='ffill', limit=None, inplace=True)\n",
        "\n",
        "  recentWWWWTIPrice=WWWTIPrice.index[-1]\n",
        "  print(WWWTIPrice)\n",
        "  return WWWTIPrice\n",
        "\n",
        "#AWTI.fillna(axis=0, method='ffill', limit=None, inplace=True)\n",
        "###########################################################################\n",
        "###OPEC Crude oil *Price*\n",
        "def OPEC():\n",
        "  import datetime\n",
        "  from datetime import datetime\n",
        "  import requests\n",
        "  import xml.etree.ElementTree as ET\n",
        "  from bs4 import BeautifulSoup\n",
        "  import numpy as np\n",
        "  import pandas as pd\n",
        "  import json\n",
        "  from google.colab import data_table\n",
        "\n",
        "  data_table.enable_dataframe_formatter()\n",
        "\n",
        "  OPECPrice=pd.read_xml('http://tempuri.org/basketDayArchives.xsd', encoding=\"utf-8\")\n",
        "  OPECPrice.head\n",
        "  OPECPrice = list(zip(pd.to_datetime(OPECPrice['data']), np.float16(OPECPrice['val'])))\n",
        "  OPECPrice=pd.DataFrame(OPECPrice)\n",
        "  OPECPrice.columns=['Date','OPEC']\n",
        "  OPECPrice['Date']=pd.to_datetime(OPECPrice['Date'],infer_datetime_format=True)\n",
        "  OPECPrice.index=OPECPrice['Date']\n",
        "  OPECPrice.sort_index\n",
        "  OOPECPrice=pd.date_range(start=f'{(OPECPrice[\"Date\"]).min()}', end=f'{OPECPrice[\"Date\"].max()}', periods=None, freq=\"D\", tz=None, normalize=False, name=None, inclusive='both')\n",
        "  OOPECPrice=pd.DataFrame(OOPECPrice)\n",
        "\n",
        "  OOPECPrice.columns=['Date']\n",
        "  OOPECPrice.index=OOPECPrice['Date']\n",
        "  OOOPECPrice=pd.concat([OOPECPrice['Date'], OPECPrice['OPEC']], axis=1, join='outer', ignore_index=False, keys=None, levels=None, names=None, verify_integrity=True, sort=True, copy=None)\n",
        "  OOOPECPrice.index=pd.to_datetime(OOOPECPrice.index,format='%Y-%m-%d',infer_datetime_format=True)\n",
        "  #OOOPECPrice.ffill()\n",
        "  #OOOPECPrice=OOOPECPrice.fillna(axis=0, method='ffill', inplace=True)\n",
        " #print(OPECPrice)\n",
        "  #PPd=OPECPrice\n",
        "  #Title and text with recent value\n",
        "  #title = f'OPEC Crude Prices '\n",
        "  #recentdt = PPd.index[-1].strftime('%B %Y')\n",
        "  #recentval = round(OPECPrice[-1], 1)\n",
        "  #recent = f'Most recent: {recentdt}: {recentval}'\n",
        "  #source = 'Source: EIA'\n",
        "  #Basic plot\n",
        "  #plot = OPECPrice.plot(title=title, colormap='copper',color='red' )\n",
        "  #plot = plot.set_xlabel(f'{recent}; {source}')\n",
        "  #OPECPrice.fillna( method=\"ffill\", axis=\"index\", inplace=True, limit=None, downcast=\"infer\")\n",
        "  #OOOPECPrice['OPEC'].fillna(axis=0, method='ffill', inplace=True)\n",
        "  #recentOOOPECPrice=OOOPECPrice.index[-1]\n",
        "  print(OOOPECPrice)\n",
        "  return OOOPECPrice\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#########################################################\n",
        "### Fuel Daily Price\n",
        "def Fuel_Daily():\n",
        "  #Fetching the bulk data from website  and reorganizing on to google drive\n",
        "  import requests\n",
        "  import json\n",
        "  import os\n",
        "  import pandas as pd\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "  Gh1files=[]\n",
        "  json_path = f\"{os.getcwd()}\\\\JSON\"\n",
        "  url = \"https://api.eia.gov/v2/petroleum/pri/spt/data/?frequency=daily&data[0]=value&facets[series][]=EER_EPD2DC_PF4_Y05LA_DPG&facets[series][]=EER_EPD2DXL0_PF4_RGC_DPG&facets[series][]=EER_EPD2DXL0_PF4_Y35NY_DPG&facets[series][]=EER_EPD2F_PF4_Y35NY_DPG&facets[series][]=EER_EPJK_PF4_RGC_DPG&facets[series][]=EER_EPLLPA_PF4_Y44MB_DPG&facets[series][]=EER_EPMRR_PF4_Y05LA_DPG&facets[series][]=EER_EPMRU_PF4_RGC_DPG&facets[series][]=EER_EPMRU_PF4_Y35NY_DPG&start=1995-01-01&sort[0][column]=period&sort[0][direction]=desc&offset=0&length=5000&api_key=7e361b53e231aaf90ac6dcd91c0dc07d\"\n",
        "  headers = {\"api_key\":\"7e361b53e231aaf90ac6dcd91c0dc07d\",\"host\":\"api.eia.gov\"}\n",
        "  # Change ticker symbol in the query string in each loop\n",
        "  #while loop\n",
        "  year = 2002\n",
        "  while year <= todays_date.year:\n",
        "\n",
        "\n",
        "    querystring={'frequency':'daily','data[0]':'value','start':f'{year}-01-01','end':f'{year}-12-31','offset':'0','length':'5000'}\n",
        "  # print(f\"year = {year}\")\n",
        "\n",
        "      # Get a new request in every loop\n",
        "    response = requests.request(\"GET\", url, headers=headers, params=querystring)\n",
        "  #print(f\"Done request {year} data\")\n",
        "\n",
        "      # Write the response into a JSON file in the JSON folder\n",
        "    with open(f\"/content/drive/MyDrive/deep learning codes/EIAAPI_DOWNLOAD/{year}pricesFuel_year.json\", \"w\") as outfile:\n",
        "      json.dump(response.json(),outfile)\n",
        "\n",
        "    #concantenating files\n",
        "    Gh1files.append(response.json())\n",
        "\n",
        "    dff = pd.DataFrame(Gh1files)\n",
        "\n",
        "      # Output message to indicate a successful loop\n",
        "   # print(f\"Wrote {year} to JSON file\")\n",
        "   # print(\"\")\n",
        "    #print('-'*30)\n",
        "   # print(\"\")\n",
        "    year += 1\n",
        "  else:\n",
        "\n",
        "      # Output message to indicate the loop is complete\n",
        "#   print(f\"Wrote all symbols to JSON file\")\n",
        "\n",
        " #  print(dff)\n",
        "\n",
        "    file =open(f\"/content/drive/MyDrive/deep learning codes/EIAAPI_DOWNLOAD/solutions/mergedata/FuelMergeddata1.json\", \"w\")\n",
        "  for item in Gh1files:\n",
        "      file.write(f\"{item}'\\n'\")\n",
        "  file.close()\n",
        "\n",
        "\n",
        "  ####################################################################################################################################\n",
        "  #Fetching Data and Reorganizing it from google drive\n",
        "  from pandas.core.generic import DataFrameFormatter\n",
        "  from numpy.core.fromnumeric import reshape\n",
        "  from pandas.core.arrays import period\n",
        "  from datetime import datetime\n",
        "  import pandas as pd\n",
        "  import json\n",
        "  import requests\n",
        "  import os\n",
        "  import numpy as np\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "  DData=[]\n",
        "  DD=[]\n",
        "  serK=[]\n",
        "  serH=[]\n",
        "  serT=[]\n",
        "  serr=[]\n",
        "  serrr=[]\n",
        "  ser=[]\n",
        "  year = 2002\n",
        "  while year < todays_date.year:\n",
        "    year += 1\n",
        "    ppperiod=[]\n",
        "    vvvvalue=[]\n",
        "\n",
        "    # Open the prices.json file\n",
        "    with open(f\"/content/drive/MyDrive/deep learning codes/EIAAPI_DOWNLOAD/{year}pricesFuel_year.json\") as file:\n",
        "\n",
        "      # Load its content and make a new dictionary\n",
        "        DData=json.load(file)\n",
        "        for response in DData:\n",
        "          DDData=(DData[\"response\"])\n",
        "\n",
        "          for data in DDData:\n",
        "            KK=[]\n",
        "            hh=[]\n",
        "            ttt=[]\n",
        "\n",
        "            DDDData=(DDData[\"data\"])\n",
        "            length = len(DDDData)\n",
        "            l=[]\n",
        "            i=0\n",
        "            while i < length:\n",
        "              v=[]\n",
        "              p=[]\n",
        "              k=DDDData[i]\n",
        "              v=k['value']\n",
        "\n",
        "              pp=(k['period'])\n",
        "              p=datetime.strptime(pp,'%Y-%m-%d').date()\n",
        "\n",
        "              tt=(k['series'])\n",
        "\n",
        "              KK.append(p)\n",
        "              hh.append(v)\n",
        "              ttt.append(tt)\n",
        "\n",
        "              i+=1\n",
        "        serK.append(KK)\n",
        "        serH.append(hh)\n",
        "        serT.append(ttt)\n",
        "  flat_list=[]\n",
        "  for sublist in serH:\n",
        "          for item in sublist:\n",
        "            flat_list.append(item)\n",
        "  flat_list1 = []\n",
        "  for sublist in serK:\n",
        "          for item in sublist:\n",
        "            flat_list1.append(item)\n",
        "  flat_list2 = []\n",
        "  for sublist in serT:\n",
        "          for item in sublist:\n",
        "            flat_list2.append(item)\n",
        "  else:\n",
        "      Price=[]\n",
        "      Date=[]\n",
        "      EER_EPD2DC_PF4_Y05LA_DPG=[]\n",
        "      EER_EPD2DXL0_PF4_RGC_DPG=[]\n",
        "      EER_EPD2DXL0_PF4_Y35NY_DPG=[]\n",
        "      EER_EPD2F_PF4_Y35NY_DPG=[]\n",
        "      EER_EPJK_PF4_RGC_DPG=[]\n",
        "      EER_EPLLPA_PF4_Y44MB_DPG=[]\n",
        "      EER_EPMRR_PF4_Y05LA_DPG=[]\n",
        "      EER_EPMRU_PF4_RGC_DPG=[]\n",
        "      EER_EPMRU_PF4_Y35NY_DP=[]\n",
        "      xx=len(flat_list1)\n",
        "\n",
        "      while i<xx-1:\n",
        "        i+=1\n",
        "        if np.mod(i,9)==0:\n",
        "          EER_EPD2DC_PF4_Y05LA_DPG.append(flat_list[i] )\n",
        "        elif np.mod(i,9)==1:\n",
        "          EER_EPD2DXL0_PF4_RGC_DPG.append(flat_list[i])\n",
        "        elif np.mod(i,9)==2:\n",
        "          EER_EPD2DXL0_PF4_Y35NY_DPG.append(flat_list[i])\n",
        "        elif np.mod(i,9)==3:\n",
        "          EER_EPD2F_PF4_Y35NY_DPG.append(flat_list[i])\n",
        "        elif np.mod(i,9)==4:\n",
        "          EER_EPJK_PF4_RGC_DPG.append(flat_list[i])\n",
        "        elif np.mod(i,9)==5:\n",
        "          EER_EPLLPA_PF4_Y44MB_DPG.append(flat_list[i])\n",
        "        elif np.mod(i,9)==6:\n",
        "          EER_EPMRR_PF4_Y05LA_DPG.append(flat_list[i])\n",
        "        elif np.mod(i,9)==7:\n",
        "          EER_EPMRU_PF4_RGC_DPG.append(flat_list[i])\n",
        "        else:\n",
        "          EER_EPMRU_PF4_Y35NY_DP.append(flat_list[i])\n",
        "          Date.append(flat_list1[i])\n",
        "\n",
        "        Price1=([Date,EER_EPD2DC_PF4_Y05LA_DPG])\n",
        "\n",
        "        Fuelprice=list(zip(Date,EER_EPD2DC_PF4_Y05LA_DPG, EER_EPD2DXL0_PF4_RGC_DPG,EER_EPD2DXL0_PF4_Y35NY_DPG, EER_EPD2F_PF4_Y35NY_DPG,\n",
        "                          EER_EPJK_PF4_RGC_DPG, EER_EPLLPA_PF4_Y44MB_DPG,EER_EPMRR_PF4_Y05LA_DPG, EER_EPMRU_PF4_RGC_DPG ,EER_EPMRU_PF4_Y35NY_DP))\n",
        "\n",
        "  Fuelprice=pd.DataFrame(Fuelprice)\n",
        "\n",
        "  Fuelprice.columns=['Date','EER_EPD2DC_PF4_Y05LA_DPG','EER_EPD2DXL0_PF4_RGC_DPG','EER_EPD2DXL0_PF4_Y35NY_DPG','EER_EPD2F_PF4_Y35NY_DPG','EER_EPJK_PF4_RGC_DPG','EER_EPLLPA_PF4_Y44MB_DPG','EER_EPMRR_PF4_Y05LA_DPG','EER_EPMRU_PF4_RGC_DPG','EER_EPMRU_PF4_Y35NY_DP']\n",
        "  Fuelprice['Date']=pd.to_datetime(Fuelprice['Date'],infer_datetime_format=True)\n",
        "  Fuelprice.index=Fuelprice['Date']\n",
        "  Fuelprice.sort_index()\n",
        "  #print(Fuelprice)\n",
        "  Fuelprice.fillna( method=\"ffill\", axis=\"index\", inplace=True, limit=None, downcast=\"infer\")\n",
        "\n",
        "  FFuelprice=pd.date_range(start=f'{(Fuelprice[\"Date\"]).min()}', end=f'{Fuelprice[\"Date\"].max()}', periods=None, freq=\"D\", tz=None, normalize=False, name=None, inclusive='both')\n",
        "  FFuelprice=pd.DataFrame(FFuelprice)\n",
        "  FFuelprice.columns=['Date']\n",
        "  FFuelprice.index=FFuelprice['Date']\n",
        "\n",
        "  FFFuelprice=pd.concat([FFuelprice['Date'], Fuelprice[['EER_EPD2DC_PF4_Y05LA_DPG','EER_EPD2DXL0_PF4_RGC_DPG','EER_EPD2DXL0_PF4_Y35NY_DPG','EER_EPD2F_PF4_Y35NY_DPG','EER_EPJK_PF4_RGC_DPG','EER_EPLLPA_PF4_Y44MB_DPG','EER_EPMRR_PF4_Y05LA_DPG','EER_EPMRU_PF4_RGC_DPG','EER_EPMRU_PF4_Y35NY_DP']]], axis=1, join='outer', ignore_index=True, keys=None, levels=None, names=None, verify_integrity=True, sort=True, copy=None)\n",
        "  FFFuelprice.columns=[['Date','EER_EPD2DC_PF4_Y05LA_DPG','EER_EPD2DXL0_PF4_RGC_DPG','EER_EPD2DXL0_PF4_Y35NY_DPG','EER_EPD2F_PF4_Y35NY_DPG','EER_EPJK_PF4_RGC_DPG','EER_EPLLPA_PF4_Y44MB_DPG','EER_EPMRR_PF4_Y05LA_DPG','EER_EPMRU_PF4_RGC_DPG','EER_EPMRU_PF4_Y35NY_DP']]\n",
        "  FFFuelprice.index=pd.to_datetime(FFFuelprice.index,format='%Y-%m-%d',infer_datetime_format=True)\n",
        "\n",
        "\n",
        "  #FFFuelprice.fillna(axis=1, method='ffill', inplace=True)\n",
        "  recentFFFuelpricee=FFFuelprice.index[-1]\n",
        "\n",
        "  print(FFFuelprice)\n",
        "  return FFFuelprice\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    #ttps://mode.com/blog/python-interactive-plot-libraries/\n",
        "    #https://note.nkmk.me/en/python-dict-keys-values-items/\n",
        "    #https://ww.freecodecamp.org/news/python-read-json-file-how-to-load-json-from-a-file-and-parse-dumps\n",
        "    #https://farama.org/Announcing-The-Farama-Foundation\n",
        "\n",
        "AAAA=Brent()\n",
        "#print(AAAA)\n",
        "BBBB=WTI()\n",
        "#print(BBBB)\n",
        "CCCC=OPEC()\n",
        "#print(CCCC)\n",
        "DDDD=Fuel_Daily()\n",
        "#print(DDDD)\n",
        "EEEE=USSDR()\n",
        "#print(EEEE)\n",
        "\n",
        "########################################\n",
        "def mergreddata():\n",
        "\n",
        "  import pandas as pd\n",
        "  ##EEEE['Date'].columns=['Date']\n",
        "  #BBrentPrice.columns=['Date']\n",
        "  #mergreddata2.index=mergreddata2['Date']\n",
        " #mergreddata2.index=pd.to_datetime(mergreddata2.index,infer_datetime_format=True)\n",
        " #mergreddata2.fillna(axis=1, method='ffill', inplace=False)\n",
        "  #mergreddata1=pd.concat([AAAA['Brent'],BBBB['WTI'],CCCC['OPEC'],EEEE['USD_SDR'],DDDD], axis=1, join='outer', ignore_index=False, levels=None, names=None, verify_integrity=True, sort=True, copy=None)\n",
        "  mergreddata1=pd.concat([EEEE['USD_SDR'],CCCC['OPEC'],AAAA['Brent'],BBBB['WTI'],DDDD], axis=1, join='outer', ignore_index=False, levels=None, names=None, verify_integrity=True, sort=True, copy=None)\n",
        "  #mergreddata1.index=mergreddata1['Date']\n",
        "  #mergreddata1.index=pd.to_datetime(mergreddata1.index,format='%Y-%m-%d',infer_datetime_format=True)\n",
        "\n",
        "  #drop_duplicates()\n",
        "  #EEEE ['Date'].columns=['Date']\n",
        " # mergreddata1.index=mergreddata1['Date']\n",
        "  #mergreddata1.index=pd.to_datetime(mergreddata1.index,infer_datetime_format=True)\n",
        "\n",
        "  #mergreddata1.fillna(axis=1, method='ffill', inplace=False)\n",
        "\n",
        "  mergreddata1.to_csv('/content/drive/MyDrive/deep learning codes/EIAAPI_DOWNLOAD/solutions/mergedata/Cleaneddata.csv', index=False)\n",
        "\n",
        "    #print(mergreddata1)\n",
        "  #recentdatadate2=mergreddata2.index[-1]\n",
        "  recentdatadate=mergreddata1.index[-1]\n",
        "  #print(recentdatadate2)\n",
        "  print(recentdatadate)\n",
        "  #print(mergreddata1)\n",
        "\n",
        "  return mergreddata1.head()\n",
        "\n",
        "FFFF=mergreddata()\n",
        "print(FFFF)\n",
        "#########################################\n",
        "\n",
        "\n",
        "\n",
        "###############################################Normalize\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lxml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qh0PdFjKROJD",
        "outputId": "76c395f3-4dbe-4a26-812d-1c1d966e4f93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (4.9.4)\n"
          ]
        }
      ]
    },
    {
      "source": [
        "!pip install lxml"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "E_vtcMkNRX68"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "import pandas as pd\n",
        "\n",
        "def OPEC():\n",
        "    OPECPrice=pd.read_xml('http://tempuri.org/basketDayArchives.xsd',\n",
        "                           parser=pd.XMLParser(schema='http://tempuri.org/basketDayArchives.xsd'))\n",
        "    return OPECPrice"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "VpedAY8mRZAr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "OPP=OPEC()\n",
        "print(OPP)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "uOqq0cMgRchy",
        "outputId": "a2ada036-84d1-413a-f6df-b15800b925fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'pandas' has no attribute 'XMLParser'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-67c2c0e4b00e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mOPP\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mOPEC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOPP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-3b00a2832d83>\u001b[0m in \u001b[0;36mOPEC\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mOPEC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     OPECPrice=pd.read_xml('http://tempuri.org/basketDayArchives.xsd',\n\u001b[0;32m----> 5\u001b[0;31m                            parser=pd.XMLParser(schema='http://tempuri.org/basketDayArchives.xsd'))\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mOPECPrice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_SparseArray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"module 'pandas' has no attribute '{name}'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'pandas' has no attribute 'XMLParser'"
          ]
        }
      ]
    },
    {
      "source": [
        "import lxml.etree"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "jwAbGXXqSdi1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "def OPEC():\n",
        "    OPECPrice=pd.read_html('http://tempuri.org/basketDayArchives.xsd')\n",
        "    return OPECPrice"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "9hgmahtzSgBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "OPP=OPEC()\n",
        "print(OPP)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "NpXwYy6MSk2d",
        "outputId": "9afa9ab4-0a0a-46fc-ad87-855b97e9ccc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "No tables found",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-67c2c0e4b00e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mOPP\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mOPEC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOPP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-3a5997112bdd>\u001b[0m in \u001b[0;36mOPEC\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mOPEC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mOPECPrice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_html\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'http://tempuri.org/basketDayArchives.xsd'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mOPECPrice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/html.py\u001b[0m in \u001b[0;36mread_html\u001b[0;34m(io, match, flavor, header, index_col, skiprows, attrs, parse_dates, thousands, encoding, decimal, converters, na_values, keep_default_na, displayed_only, extract_links)\u001b[0m\n\u001b[1;32m   1203\u001b[0m     \u001b[0mio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstringify_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1205\u001b[0;31m     return _parse(\n\u001b[0m\u001b[1;32m   1206\u001b[0m         \u001b[0mflavor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflavor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1207\u001b[0m         \u001b[0mio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/html.py\u001b[0m in \u001b[0;36m_parse\u001b[0;34m(flavor, io, match, attrs, encoding, displayed_only, extract_links, **kwargs)\u001b[0m\n\u001b[1;32m   1004\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mretained\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# for mypy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1006\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mretained\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1007\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1008\u001b[0m     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/html.py\u001b[0m in \u001b[0;36m_parse\u001b[0;34m(flavor, io, match, attrs, encoding, displayed_only, extract_links, **kwargs)\u001b[0m\n\u001b[1;32m    984\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m             \u001b[0mtables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_tables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcaught\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m             \u001b[0;31m# if `io` is an io-like object, check if it's seekable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/html.py\u001b[0m in \u001b[0;36mparse_tables\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mparsed\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfooter\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mtuples\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \"\"\"\n\u001b[0;32m--> 262\u001b[0;31m         \u001b[0mtables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_tables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_doc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_thead_tbody_tfoot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtable\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/html.py\u001b[0m in \u001b[0;36m_parse_tables\u001b[0;34m(self, doc, match, attrs)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No tables found\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: No tables found"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "def OPEC():\n",
        "    url = \"https://www.opec.org/opec-basket-price\"\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "    table = soup.find_all(\"table\", class_=\"basket-price-table\")[1]\n",
        "    data = []\n",
        "    for row in table.find_all(\"tr\")[1:]:\n",
        "        cells = row.find_all(\"td\")\n",
        "        date = datetime.strptime(cells[0].text.strip(), \"%d %b %Y\")\n",
        "        price = float(cells[1].text.strip().replace(\",\", \"\"))\n",
        "        data.append({\"date\": date, \"price\": price})\n",
        "    df = pd.DataFrame(data)\n",
        "    df.set_index(\"date\", inplace=True)\n",
        "    return df"
      ],
      "metadata": {
        "id": "oEOsvtdS084_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "A=OPEC()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "1hVmnlE21VMD",
        "outputId": "f08520da-d607-4ccd-dcae-dfcd1d79add1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "list index out of range",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-ceea2469cff5>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mA\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mOPEC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-18-b18155edbc67>\u001b[0m in \u001b[0;36mOPEC\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"html.parser\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"table\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"basket-price-table\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tr\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(A)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "id": "u-TX9ahs0_bh",
        "outputId": "af7452d7-7a96-481c-94a6-f10cdeb4712a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-2a851eda2e88>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://www.opec.org/opec-basket-price\"\n",
        "response = requests.get(url)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3IqaXat1jUR",
        "outputId": "ad660241-d138-4619-92b7-cfd99e62db20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<Response [403]>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "OPECPrice=pd.read_xml('http://tempuri.org/basketDayArchives.xsd', encoding=\"utf-8\")"
      ],
      "metadata": {
        "id": "BfZoG3x7kZHf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import requests\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "def loadRSS():\n",
        "\n",
        "    # url of rss feed\n",
        "    url = 'http://tempuri.org/basketDayArchives.xsd'\n",
        "\n",
        "    # creating HTTP response object from given url\n",
        "    resp = requests.get(url)\n",
        "\n",
        "    # saving the xml file\n",
        "    with open('topnewsfeed.xml', 'wb') as f:\n",
        "        f.write(resp.content)\n",
        "\n",
        "\n",
        "def parseXML(xmlfile):\n",
        "\n",
        "    # create element tree object\n",
        "    tree = ET.parse(xmlfile)\n",
        "\n",
        "    # get root element\n",
        "    root = tree.getroot()\n",
        "\n",
        "    # create empty list for news items\n",
        "    newsitems = []\n",
        "\n",
        "    # iterate news items\n",
        "    for item in root.findall('./channel/item'):\n",
        "\n",
        "        # empty news dictionary\n",
        "        news = {}\n",
        "\n",
        "        # iterate child elements of item\n",
        "        for child in item:\n",
        "\n",
        "            # special checking for namespace object content:media\n",
        "            if child.tag == '{http://search.yahoo.com/mrss/}content':\n",
        "                news['media'] = child.attrib['url']\n",
        "            else:\n",
        "                news[child.tag] = child.text.encode('utf8')\n",
        "\n",
        "        # append news dictionary to news items list\n",
        "        newsitems.append(news)\n",
        "\n",
        "    # return news items list\n",
        "    return newsitems\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "-HCK6TRZgt2f",
        "outputId": "3689949d-9691-44a9-de32-31412a866e50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ParseError",
          "evalue": "syntax error: line 1, column 0 (<string>)",
          "traceback": [
            "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
            "  File \u001b[1;32m\"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m3553\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \u001b[1;32m\"<ipython-input-20-ad8fe4db352c>\"\u001b[0m, line \u001b[1;32m83\u001b[0m, in \u001b[1;35m<cell line: 80>\u001b[0m\n    main()\n",
            "  File \u001b[1;32m\"<ipython-input-20-ad8fe4db352c>\"\u001b[0m, line \u001b[1;32m74\u001b[0m, in \u001b[1;35mmain\u001b[0m\n    newsitems = parseXML('topnewsfeed.xml')\n",
            "  File \u001b[1;32m\"<ipython-input-20-ad8fe4db352c>\"\u001b[0m, line \u001b[1;32m21\u001b[0m, in \u001b[1;35mparseXML\u001b[0m\n    tree = ET.parse(xmlfile)\n",
            "  File \u001b[1;32m\"/usr/lib/python3.10/xml/etree/ElementTree.py\"\u001b[0m, line \u001b[1;32m1222\u001b[0m, in \u001b[1;35mparse\u001b[0m\n    tree.parse(source, parser)\n",
            "\u001b[0;36m  File \u001b[0;32m\"/usr/lib/python3.10/xml/etree/ElementTree.py\"\u001b[0;36m, line \u001b[0;32m580\u001b[0;36m, in \u001b[0;35mparse\u001b[0;36m\u001b[0m\n\u001b[0;31m    self._root = parser._parse_whole(source)\u001b[0m\n",
            "\u001b[0;36m  File \u001b[0;32m\"<string>\"\u001b[0;36m, line \u001b[0;32munknown\u001b[0m\n\u001b[0;31mParseError\u001b[0m\u001b[0;31m:\u001b[0m syntax error: line 1, column 0\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}